# COMP700-HonoursProject
Project Name: Automatic Acoustic Classification of Birds Using Autoencoders
Student number: 218035344

Links to Dataset: 
The following datasets were used: 
1. xccoverbl: a subset of bird sound recordings commonly heard in the United Kingdom, collected from the Xeno Canto collection. The recordings are in .flac format. Found at (https://archive.org/details/xccoverbl_2014)
2. bird song dataset:  a subset of bird song recordings from the Xeno Canto collection. The collection contains recordings from 5 species: Bewickâ€™s Wren, Northern Cardinal, American Robin, Song Sparrow, and Northern Mockingbird. These recordings are in .wav format. Found at (https://www.kaggle.com/datasets/vinayshanbhag/bird-song-data-set?select=wavfiles)
3. nips4b: This dataset was procured from the Bird NIPS4B competition. Found at: (https://www.kaggle.com/competitions/multilabel-bird-species-classification-nips2013/rules). Only the nips4b train set and the nips4b_bird_challenge_train_labels were used from the folder. 

Running the code: 
The code can be run with minimal changes. The only changes to be made are to the dataset path names that the user has downloaded to match those used in the code. If the user is not uploading the datasets via google drive, the first block of code can be commented out. 

Sources: 
1. https://www.v7labs.com/blog/autoencoders-guide
2. https://prog.world/how-to-convert-audio-data-to-images/
3. https://www.kaggle.com/code/msripooja/steps-to-convert-audio-clip-to-spectrogram/notebook
4. https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5
5. https://www.kaggle.com/code/fleanend/extract-features-with-librosa-predict-with-nb
6. https://blog.keras.io/building-autoencoders-in-keras.html
7. https://towardsdatascience.com/sound-based-bird-classification-965d0ecacb2b
8. https://www.kaggle.com/c/birdclef-2021/discussion/230043
9. https://zenodo.org/record/1208080#.Y3EtV3ZBzre
10. https://www.analyticsvidhya.com/blog/2022/03/implementing-audio-classification-project-using-deep-learning/
11. https://www.kaggle.com/code/sreevaatsavbavana/sound-classifiaction-using-ml-and-deep-learning
12. https://jonathan-hui.medium.com/speech-recognition-feature-extraction-mfcc-plp-5455f5a69dd9
13. https://machinelearningmastery.com/autoencoder-for-regression/
14. https://towardsdatascience.com/recurrent-neural-nets-for-audio-classification-81cb62327990
15. https://www.researchgate.net/post/Why_we_take_only_12-13_MFCC_coefficients_in_feature_extraction
16. https://www.datacamp.com/tutorial/autoencoder-classifier-python
17. https://towardsdatascience.com/cnns-for-audio-classification-6244954665ab
18. https://stackoverflow.com/questions/62186487/how-to-decide-the-size-of-image-for-spectrogram-based-on-audio-length
19. https://www.section.io/engineering-education/machine-learning-for-audio-classification/
20. https://www.tensorflow.org/tutorials/generative/autoencoder
21. https://stackoverflow.com/questions/9458480/read-mp3-in-python-3
